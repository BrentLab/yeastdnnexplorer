{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to perform a hyperparameter sweep for the customizable model.\n",
    "We also will be using the TF dependent adjustment function to closer mimic the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "from pytorch_lightning import Trainer, LightningModule, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "from torchsummary import summary\n",
    "\n",
    "from yeastdnnexplorer.data_loaders.synthetic_data_loader import SyntheticDataLoader\n",
    "from yeastdnnexplorer.ml_models.simple_model import SimpleModel\n",
    "from yeastdnnexplorer.ml_models.customizable_model import CustomizableModel\n",
    "\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from yeastdnnexplorer.probability_models.generate_data import (\n",
    "    perturbation_effect_adjustment_function_with_tf_relationships,\n",
    ")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoints for the model\n",
    "# tells it when to save snapshots of the model during training\n",
    "# Callback to save the best model based on validation loss\n",
    "best_model_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"best-model-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "# Callback to save checkpoints every 5 epochs, regardless of performance\n",
    "periodic_checkpoint = ModelCheckpoint(\n",
    "    filename=\"periodic-{epoch:02d}\",\n",
    "    every_n_epochs=2,\n",
    "    save_top_k=-1,  # Setting -1 saves all checkpoints\n",
    ")\n",
    "\n",
    "# define loggers for the model# configure loggers\n",
    "tb_logger = TensorBoardLogger(\"logs/tensorboard_logs\")\n",
    "csv_logger = CSVLogger(\"logs/csv_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old scratch work [PROOF that a good model is learning nonlinear deps introduced by tf_relationships_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:244: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, Y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val, Y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:250: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, Y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | ReLU       | 0     \n",
      "1 | input_layer   | Linear     | 1.8 K \n",
      "2 | hidden_layers | ModuleList | 10.3 K\n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "12.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0753b1e63aa74d40bbbf5f90334ace3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ffc0c59ae462a8290097b3b20b458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbeccc95dda4ca8ac5601d58a5bb7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2841460abb4252bf67af983ee8853c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d010dc20d2c4ec986ebf801cc814ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdf6da375a847eb8550266c0835651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf80f98c23634654a18d92d2d61bf321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dddbf291a14123b2c679fd064c5177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6457d1ce39da40e18529eb6117eb8614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec94ba0384f34d48911b19e4839469d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ec6ad3e33b435a8986c5c17033084e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb498cce66e841a8a579cd70c75ee236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5427e414a7043b78c1249c3dfb66037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.7528094053268433\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Printing test results...\n",
      "[{'test_loss': 1.7528094053268433}]\n",
      "Printing model summary...\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 13, 128]           1,792\n",
      "              ReLU-2              [-1, 13, 128]               0\n",
      "           Dropout-3              [-1, 13, 128]               0\n",
      "            Linear-4               [-1, 13, 64]           8,256\n",
      "              ReLU-5               [-1, 13, 64]               0\n",
      "           Dropout-6               [-1, 13, 64]               0\n",
      "            Linear-7               [-1, 13, 32]           2,080\n",
      "              ReLU-8               [-1, 13, 32]               0\n",
      "           Dropout-9               [-1, 13, 32]               0\n",
      "           Linear-10               [-1, 13, 13]             429\n",
      "================================================================\n",
      "Total params: 12,557\n",
      "Trainable params: 12,557\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tf_relationships_dict = {\n",
    "    0: [2, 4, 7],\n",
    "    1: [8],\n",
    "    2: [3, 9],\n",
    "    3: [1, 6],\n",
    "    4: [5],\n",
    "    5: [0, 2, 8],\n",
    "    6: [4],\n",
    "    7: [1, 4],\n",
    "    8: [6],\n",
    "    9: [0, 3, 8],\n",
    "}\n",
    "\n",
    "data_module = SyntheticDataLoader(\n",
    "    batch_size=32,\n",
    "    num_genes=4000,\n",
    "    signal_mean=3.0,\n",
    "    signal=[0.5] * 10,  # old: [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    n_sample=[1, 2, 2, 4, 4],  # sum of this is num of tfs\n",
    "    val_size=0.1,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    max_mean_adjustment=3.0,\n",
    "    adjustment_function=perturbation_effect_adjustment_function_with_tf_relationships,\n",
    "    tf_relationships=tf_relationships_dict,\n",
    ")\n",
    "\n",
    "num_tfs = sum(data_module.n_sample)  # sum of all n_sample is the number of TFs\n",
    "\n",
    "model = CustomizableModel(\n",
    "    input_dim=num_tfs,\n",
    "    output_dim=num_tfs,\n",
    "    lr=0.01,\n",
    "    hidden_layer_num=3,\n",
    "    hidden_layer_sizes=[128, 64, 32],\n",
    "    activation=\"ReLU\",\n",
    "    optimizer=\"Adam\",\n",
    "    L2_regularization_term=0.0,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    deterministic=True,\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[best_model_checkpoint, periodic_checkpoint],\n",
    "    logger=[tb_logger, csv_logger],\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "test_results = trainer.test(model, datamodule=data_module)\n",
    "print(\"Printing test results...\")\n",
    "print(test_results)  # this prints all metrics that were logged during the test phase\n",
    "\n",
    "# print summary of model\n",
    "print(\"Printing model summary...\")\n",
    "summary(model, (num_tfs, num_tfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tf relationships dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_relationships_dict = {\n",
    "    0: [2, 4, 7],\n",
    "    1: [8],\n",
    "    2: [3, 9],\n",
    "    3: [1, 6],\n",
    "    4: [5],\n",
    "    5: [0, 2, 8],\n",
    "    6: [4],\n",
    "    7: [1, 4],\n",
    "    8: [6],\n",
    "    9: [0, 3, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective function for our hyperparam sweep (and decide on what we want to sweep through)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "# input_dim: int,\n",
    "# output_dim: int,\n",
    "# lr: float = 0.001,\n",
    "# hidden_layer_num: int = 1,\n",
    "# hidden_layer_sizes: list = [128],\n",
    "# activation: str = \"ReLU\", # can be \"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\"\n",
    "# optimizer: str = \"Adam\", # can be \"Adam\", \"SGD\", \"RMSprop\"\n",
    "# L2_regularization_term: float = 0.0,\n",
    "# dropout_rate: float = 0.0,\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # model hyperparameters\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    hidden_layer_num = trial.suggest_categorical(\"hidden_layer_num\", [1, 2, 3, 5])\n",
    "    activation = trial.suggest_categorical(\n",
    "        \"activation\", [\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\"]\n",
    "    )\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    L2_regularization_term = trial.suggest_categorical(\n",
    "        \"L2_regularization_term\", [0, 0.1, 0.01]\n",
    "    )  # change to categorical?\n",
    "    dropout_rate = trial.suggest_categorical(\n",
    "        \"dropout_rate\", [0, 0.3, 0.5]\n",
    "    )  # change to categorical?\n",
    "\n",
    "    # data module hyperparameters\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 128])\n",
    "\n",
    "    # training hyperparameters\n",
    "    max_epochs = trial.suggest_categorical(\n",
    "        \"max_epochs\", [2]\n",
    "    )  # can keep this low for sanity check\n",
    "\n",
    "    # defining what to pass in for the hidden layer sizes list based on the number of hidden layers\n",
    "    hidden_layer_sizes_configurations = {\n",
    "        1: [[64], [256]],\n",
    "        2: [[64, 32], [256, 64]],\n",
    "        3: [[256, 128, 32]],\n",
    "        5: [[512, 256, 128, 64, 32]],\n",
    "    }\n",
    "    hidden_layer_sizes = trial.suggest_categorical(\n",
    "        f\"hidden_layer_sizes_{hidden_layer_num}_layers\",\n",
    "        hidden_layer_sizes_configurations[hidden_layer_num],\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"About to create model with the following hyperparameters:\")\n",
    "    print(f\"lr: {lr}\")\n",
    "    print(f\"hidden_layer_num: {hidden_layer_num}\")\n",
    "    print(f\"hidden_layer_sizes: {hidden_layer_sizes}\")\n",
    "    print(f\"activation: {activation}\")\n",
    "    print(f\"optimizer: {optimizer}\")\n",
    "    print(f\"L2_regularization_term: {L2_regularization_term}\")\n",
    "    print(f\"dropout_rate: {dropout_rate}\")\n",
    "    print(f\"batch_size: {batch_size}\")\n",
    "    print(f\"max_epochs: {max_epochs}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # create data module\n",
    "    data_module = SyntheticDataLoader(\n",
    "        batch_size=batch_size,\n",
    "        num_genes=4000,\n",
    "        signal_mean=3.0,\n",
    "        signal=[0.5] * 10,  # old: [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "        n_sample=[1, 2, 2, 4, 4],  # sum of this is num of tfs\n",
    "        val_size=0.1,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        max_mean_adjustment=3.0,\n",
    "        adjustment_function=perturbation_effect_adjustment_function_with_tf_relationships,\n",
    "        tf_relationships=tf_relationships_dict,\n",
    "    )\n",
    "\n",
    "    num_tfs = sum(data_module.n_sample)  # sum of all n_sample is the number of TFs\n",
    "\n",
    "    # create model\n",
    "    model = CustomizableModel(\n",
    "        input_dim=num_tfs,\n",
    "        output_dim=num_tfs,\n",
    "        lr=lr,\n",
    "        hidden_layer_num=hidden_layer_num,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        optimizer=optimizer,\n",
    "        L2_regularization_term=L2_regularization_term,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "\n",
    "    # create trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        deterministic=True,\n",
    "        accelerator=\"cpu\",\n",
    "        callbacks=[\n",
    "            best_model_checkpoint\n",
    "        ],  # not using periodic checkpoint as that would be way too many checkpoints, can add back if we choose a specific hyperparam config that we want to look more closely at\n",
    "        logger=[tb_logger, csv_logger],\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # get best validation loss from the model\n",
    "    return trainer.callback_metrics[\"val_loss\"]  # TODO is .item() needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the hyperparam sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-18 10:30:40,965] A new study created in memory with name: no-name-a994b30b-aa3d-4830-8de9-152b9aaaab76\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.001\n",
      "hidden_layer_num: 1\n",
      "hidden_layer_sizes: [64]\n",
      "activation: ReLU\n",
      "optimizer: Adam\n",
      "L2_regularization_term: 0.01\n",
      "dropout_rate: 0.5\n",
      "batch_size: 32\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:231: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, Y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:234: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val, Y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/yeastdnnexplorer/data_loaders/synthetic_data_loader.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, Y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | ReLU       | 0     \n",
      "1 | input_layer   | Linear     | 896   \n",
      "2 | hidden_layers | ModuleList | 0     \n",
      "3 | output_layer  | Linear     | 845   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d797b865104ddc8617612ff21482c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc397be9e2894596bfb9899d082f5206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebefb99e5ade41e7b2df6c94c8862616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e30b6c8a44edaabd57e62125838a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:04,540] Trial 0 finished with value: 4.347833156585693 and parameters: {'lr': 0.001, 'hidden_layer_num': 1, 'activation': 'ReLU', 'optimizer': 'Adam', 'L2_regularization_term': 0.01, 'dropout_rate': 0.5, 'batch_size': 32, 'max_epochs': 2, 'hidden_layer_sizes_1_layers': [64]}. Best is trial 0 with value: 4.347833156585693.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 128, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 3\n",
      "hidden_layer_sizes: [256, 128, 32]\n",
      "activation: LeakyReLU\n",
      "optimizer: RMSprop\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory logs/tensorboard_logs/lightning_logs/version_60/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | LeakyReLU  | 0     \n",
      "1 | input_layer   | Linear     | 3.6 K \n",
      "2 | hidden_layers | ModuleList | 37.0 K\n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "41.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.0 K    Total params\n",
      "0.164     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330d5fcc57514ee6886b77ede16523c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a285072494d7da9c48289075f4910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3957ba9871468bbf7f4cfc35e981aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cb41fe686c4e6a9fb3b892afc9733b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:25,804] Trial 1 finished with value: 49579.48828125 and parameters: {'lr': 0.1, 'hidden_layer_num': 3, 'activation': 'LeakyReLU', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_3_layers': [256, 128, 32]}. Best is trial 0 with value: 4.347833156585693.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 1\n",
      "hidden_layer_sizes: [64]\n",
      "activation: Tanh\n",
      "optimizer: Adam\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 32\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 896   \n",
      "2 | hidden_layers | ModuleList | 0     \n",
      "3 | output_layer  | Linear     | 845   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc4727d3dad4d9384c52c18310dfd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6411211f38492987f4db22a88323c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70562067c7564f31a02e7e80ef97162a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ebae09795d41c388fb4cc02db3fb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:31:48,495] Trial 2 finished with value: 2.718580961227417 and parameters: {'lr': 0.1, 'hidden_layer_num': 1, 'activation': 'Tanh', 'optimizer': 'Adam', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 32, 'max_epochs': 2, 'hidden_layer_sizes_1_layers': [64]}. Best is trial 2 with value: 2.718580961227417.\n",
      "/Users/benmueller/2024Classes/BrentResearch/git_repos/yeastdnnexplorer/.venv/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 256, 128, 64, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.1\n",
      "hidden_layer_num: 5\n",
      "hidden_layer_sizes: [512, 256, 128, 64, 32]\n",
      "activation: Tanh\n",
      "optimizer: SGD\n",
      "L2_regularization_term: 0\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 7.2 K \n",
      "2 | hidden_layers | ModuleList | 174 K \n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "182 K     Trainable params\n",
      "0         Non-trainable params\n",
      "182 K     Total params\n",
      "0.729     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420db7d8c28846adb2931babfcab3845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce981f8ac564d908b75bfaf21f050de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f55b71e181b43229b0883a279dd0e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522198a66442444290382c58cf8c44e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:32:10,222] Trial 3 finished with value: 2.8252861499786377 and parameters: {'lr': 0.1, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'SGD', 'L2_regularization_term': 0, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}. Best is trial 2 with value: 2.718580961227417.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "About to create model with the following hyperparameters:\n",
      "lr: 0.01\n",
      "hidden_layer_num: 5\n",
      "hidden_layer_sizes: [512, 256, 128, 64, 32]\n",
      "activation: Tanh\n",
      "optimizer: RMSprop\n",
      "L2_regularization_term: 0.1\n",
      "dropout_rate: 0.3\n",
      "batch_size: 128\n",
      "max_epochs: 2\n",
      "\n",
      "bm - adjustment function provided to dataLoader setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | activation    | Tanh       | 0     \n",
      "1 | input_layer   | Linear     | 7.2 K \n",
      "2 | hidden_layers | ModuleList | 174 K \n",
      "3 | output_layer  | Linear     | 429   \n",
      "4 | dropout       | Dropout    | 0     \n",
      "---------------------------------------------\n",
      "182 K     Trainable params\n",
      "0         Non-trainable params\n",
      "182 K     Total params\n",
      "0.729     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6e0ee69284fb0bbf6b779e6007c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8044311dc429dbed26cc59b9e3431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdfe044ce93491aba9b9210713416ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33a692c805247b08668a0f29675e1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2024-03-18 10:32:32,349] Trial 4 finished with value: 2.3827872276306152 and parameters: {'lr': 0.01, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}. Best is trial 4 with value: 2.3827872276306152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RESULTS======================================================================\n",
      "Best hyperparameters: {'lr': 0.01, 'hidden_layer_num': 5, 'activation': 'Tanh', 'optimizer': 'RMSprop', 'L2_regularization_term': 0.1, 'dropout_rate': 0.3, 'batch_size': 128, 'max_epochs': 2, 'hidden_layer_sizes_5_layers': [512, 256, 128, 64, 32]}\n",
      "Best loss: 2.3827872276306152\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter optimization using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Get the best hyperparameters and their corresponding values\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"\\n\" * 5)\n",
    "print(\"RESULTS\" + (\"=\" * 70))\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best loss: {best_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
