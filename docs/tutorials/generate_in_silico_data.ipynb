{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yeastdnnexplorer.probability_models.generate_data import (generate_gene_population, \n",
    "                                                               generate_binding_effects,\n",
    "                                                               generate_pvalues,\n",
    "                                                               generate_perturbation_effects)\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)  # For CPU\n",
    "torch.cuda.manual_seed_all(42)  # For all CUDA devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Set of Data\n",
    "\n",
    "### Step 1:\n",
    "\n",
    "The first step is to generate a gene population, or set of gene populations.\n",
    "A gene population is simply a class that stores a 1D tensor called `labels`.\n",
    "`labels` is a boolean vector where 1 means the gene is part of the signal group\n",
    "(a gene which is both bound and responsive to the TF) while 0 means the gene is\n",
    "part of the background or noise group. The length of `labels` is the number of\n",
    "genes in the population, and the index should be considered the unique gene\n",
    "identifier. In other words, the indicies should never change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = 1000\n",
    "signal = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "n_sample = [1, 1, 2, 2, 4]\n",
    "\n",
    "# this will be a list of length 10 with a GenePopulation object in each element\n",
    "gene_populations_list = []\n",
    "for signal_proportion, n_draws in zip(signal, n_sample):\n",
    "    for _ in range(n_draws):\n",
    "        gene_populations_list.append(generate_gene_population(n_genes, signal_proportion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "The second step is to generate binding data from the gene population(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the binding data tensor: torch.Size([1000, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# Generate binding data for each gene population\n",
    "binding_effect_list = [generate_binding_effects(gene_population)\n",
    "                     for gene_population in gene_populations_list]\n",
    "\n",
    "\n",
    "# Calculate p-values for binding data\n",
    "binding_pvalue_list = [generate_pvalues(binding_data) for binding_data in binding_effect_list]\n",
    "\n",
    "binding_data_combined = [torch.stack((gene_population.labels, binding_effect, binding_pval), dim=1)\n",
    "                         for gene_population, binding_effect, binding_pval\n",
    "                         in zip (gene_populations_list, binding_effect_list, binding_pvalue_list)]\n",
    "\n",
    "# Stack along a new dimension (dim=1) to create a tensor of shape [num_genes, num_TFs, 3]\n",
    "binding_data_tensor = torch.stack(binding_data_combined, dim=1)\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Shape of the binding data tensor:\", binding_data_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate perturbation data.\n",
    "\n",
    "Note that you can optionally use the binding enrichment data across one or more\n",
    "TFs to probabilistically increase the chance of a larger perturbation effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that you could use different settings for the perturbation effects\n",
    "# for each TF, or possibly use the n_samples vector from step 1. You also have\n",
    "# the option of using all or some of the TFs to conditionally affect the\n",
    "# binding score. See `generate_perturbation_effects()` in the help or the\n",
    "# documentation for more details.\n",
    "perturbation_effects_list = [generate_perturbation_effects(binding_data_tensor)\n",
    "                             for _ in range(sum(n_sample))]\n",
    "\n",
    "perturbation_pvalue_list = [generate_pvalues(perturbation_effects)\n",
    "                            for perturbation_effects in perturbation_effects_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Assemble\n",
    "\n",
    "The final step is to assemble the data into a single tensor. Here is one way.\n",
    "The order of the matrix in the last dimension is:\n",
    "\n",
    "1. signal/noise label\n",
    "1. binding effect\n",
    "1. binding pvalue\n",
    "1. perturbation effect\n",
    "1. perturbation pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final data tensor: torch.Size([1000, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to tensors if they are not already\n",
    "perturbation_effects_tensor = torch.stack(perturbation_effects_list, dim=1)\n",
    "perturbation_pvalues_tensor = torch.stack(perturbation_pvalue_list, dim=1)\n",
    "\n",
    "# Ensure perturbation data is reshaped to match [n_genes, n_tfs]\n",
    "# This step might need adjustment based on the actual shapes of your tensors.\n",
    "perturbation_effects_tensor = perturbation_effects_tensor.unsqueeze(-1)  # Adds an extra dimension for concatenation\n",
    "perturbation_pvalues_tensor = perturbation_pvalues_tensor.unsqueeze(-1)  # Adds an extra dimension for concatenation\n",
    "\n",
    "# Concatenate along the last dimension to form a [n_genes, n_tfs, 5] tensor\n",
    "final_data_tensor = torch.cat((binding_data_tensor, perturbation_effects_tensor, perturbation_pvalues_tensor), dim=2)\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Shape of the final data tensor:\", final_data_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, I choose to structure the data this way by looking at the\n",
    "result of strides, which describes how the data is stored in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3, 1)\n",
      "(300, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor_continuous = torch.empty(100, 1000, 3)\n",
    "strides_continuous = tensor_continuous.stride()\n",
    "print(strides_continuous)\n",
    "\n",
    "\n",
    "tensor_continuous = torch.empty(1000, 100, 3)\n",
    "strides_continuous = tensor_continuous.stride()\n",
    "print(strides_continuous)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
